{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üî§ NOTEBOOK 4: Procesamiento de Texto con Scikit-learn\n",
        "\n",
        "## üéØ ¬øQu√© aprender√°s en este notebook?\n",
        "\n",
        "Los modelos de Machine Learning **solo entienden n√∫meros**, no texto. Por eso necesitamos **convertir palabras en vectores num√©ricos**.\n",
        "\n",
        "En este notebook aprender√°s:\n",
        "1. ‚úÖ Qu√© es el procesamiento de texto (NLP b√°sico)\n",
        "2. ‚úÖ Bag of Words: convertir frases en vectores\n",
        "3. ‚úÖ CountVectorizer: la herramienta principal\n",
        "4. ‚úÖ Explorar el vocabulario y la matriz de caracter√≠sticas\n",
        "5. ‚úÖ train_test_split: dividir datos correctamente\n",
        "6. ‚úÖ Preparar datos para el clasificador de sentimientos\n",
        "\n",
        "**‚è±Ô∏è Duraci√≥n estimada:** 90 minutos\n",
        "\n",
        "---\n",
        "\n",
        "## üìö ¬øPor qu√© procesar texto?\n",
        "\n",
        "**Problema:** Las redes neuronales trabajan con n√∫meros (matrices), no con palabras.\n",
        "\n",
        "**Soluci√≥n:** Convertir texto ‚Üí n√∫meros usando t√©cnicas de NLP.\n",
        "\n",
        "**Ejemplo:**\n",
        "```\n",
        "\"Me gusta este producto\" ‚Üí [1, 1, 1, 1, 0, 0, 0, ...]\n",
        "\"Este producto es malo\"   ‚Üí [0, 1, 1, 1, 1, 0, 1, ...]\n",
        "```\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì¶ PASO 1: Importar librer√≠as"
      ],
      "metadata": {
        "id": "step1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"‚úÖ Librer√≠as importadas correctamente\")"
      ],
      "metadata": {
        "id": "imports",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24bdd3ea-6222-402f-d934-3d6c48b1ae64"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Librer√≠as importadas correctamente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üéí PASO 2: ¬øQu√© es Bag of Words?\n",
        "\n",
        "### üìñ Teor√≠a: Representaci√≥n de texto\n",
        "\n",
        "**Bag of Words (Bolsa de Palabras)** es la t√©cnica m√°s simple para convertir texto en n√∫meros:\n",
        "\n",
        "1. **Crea un vocabulario** con todas las palabras √∫nicas\n",
        "2. **Cada frase se convierte en un vector** donde:\n",
        "   - Posici√≥n i = 1 si la palabra i aparece\n",
        "   - Posici√≥n i = 0 si no aparece\n",
        "\n",
        "**Ejemplo visual:**\n",
        "\n",
        "```\n",
        "Frases:\n",
        "1. \"me gusta este producto\"\n",
        "2. \"este producto es malo\"\n",
        "\n",
        "Vocabulario: [me, gusta, este, producto, es, malo]\n",
        "                0    1     2       3      4    5\n",
        "\n",
        "Vectores:\n",
        "Frase 1: [1, 1, 1, 1, 0, 0]  ‚Üê tiene \"me\", \"gusta\", \"este\", \"producto\"\n",
        "Frase 2: [0, 0, 1, 1, 1, 1]  ‚Üê tiene \"este\", \"producto\", \"es\", \"malo\"\n",
        "```\n",
        "\n",
        "### üß™ EJEMPLO RESUELTO: Bag of Words manual"
      ],
      "metadata": {
        "id": "step2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo manual para entender el concepto\n",
        "frases = [\n",
        "    \"me gusta programar\",\n",
        "    \"me gusta python\",\n",
        "    \"python es genial\"\n",
        "]\n",
        "\n",
        "print(\"üìù FRASES ORIGINALES:\")\n",
        "for i, frase in enumerate(frases, 1):\n",
        "    print(f\"   {i}. {frase}\")\n",
        "print()\n",
        "\n",
        "# Paso 1: Crear vocabulario (palabras √∫nicas)\n",
        "vocabulario = set()\n",
        "for frase in frases:\n",
        "    palabras = frase.split()\n",
        "    vocabulario.update(palabras)\n",
        "\n",
        "vocabulario = sorted(vocabulario)  # Ordenar alfab√©ticamente\n",
        "\n",
        "print(\"üìñ VOCABULARIO (palabras √∫nicas):\")\n",
        "for i, palabra in enumerate(vocabulario):\n",
        "    print(f\"   Posici√≥n {i}: '{palabra}'\")\n",
        "print()\n",
        "\n",
        "# Paso 2: Convertir cada frase a vector\n",
        "print(\"üî¢ VECTORES (Bag of Words):\")\n",
        "for frase in frases:\n",
        "    palabras = frase.split()\n",
        "    vector = [1 if palabra in palabras else 0 for palabra in vocabulario]\n",
        "    print(f\"   '{frase}' ‚Üí {vector}\")\n",
        "print()\n",
        "\n",
        "print(\"üí° INTERPRETACI√ìN:\")\n",
        "print(\"   - Cada posici√≥n representa una palabra del vocabulario\")\n",
        "print(\"   - 1 = la palabra aparece en la frase\")\n",
        "print(\"   - 0 = la palabra NO aparece en la frase\")"
      ],
      "metadata": {
        "id": "example_bow_manual",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4302b0e3-581d-4d74-ebce-c297f7466542"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìù FRASES ORIGINALES:\n",
            "   1. me gusta programar\n",
            "   2. me gusta python\n",
            "   3. python es genial\n",
            "\n",
            "üìñ VOCABULARIO (palabras √∫nicas):\n",
            "   Posici√≥n 0: 'es'\n",
            "   Posici√≥n 1: 'genial'\n",
            "   Posici√≥n 2: 'gusta'\n",
            "   Posici√≥n 3: 'me'\n",
            "   Posici√≥n 4: 'programar'\n",
            "   Posici√≥n 5: 'python'\n",
            "\n",
            "üî¢ VECTORES (Bag of Words):\n",
            "   'me gusta programar' ‚Üí [0, 0, 1, 1, 1, 0]\n",
            "   'me gusta python' ‚Üí [0, 0, 1, 1, 0, 1]\n",
            "   'python es genial' ‚Üí [1, 1, 0, 0, 0, 1]\n",
            "\n",
            "üí° INTERPRETACI√ìN:\n",
            "   - Cada posici√≥n representa una palabra del vocabulario\n",
            "   - 1 = la palabra aparece en la frase\n",
            "   - 0 = la palabra NO aparece en la frase\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚úçÔ∏è AHORA T√ö: Crea tu propio Bag of Words\n",
        "\n",
        "**Completa el c√≥digo siguiente:**"
      ],
      "metadata": {
        "id": "exercise2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EJERCICIO 1: Completa el proceso manual de Bag of Words\n",
        "#\n",
        "# üí° PISTA GLOBAL:\n",
        "# - Necesitas dividir cada frase en palabras usando un m√©todo de strings\n",
        "# - Los sets tienen un m√©todo para a√±adir m√∫ltiples elementos de una vez\n",
        "# - Las comprensiones de lista verifican condiciones con 'in'\n",
        "# - Para ordenar iterables existe una funci√≥n built-in que devuelve una lista\n",
        "# - Revisa el ejemplo anterior para recordar los nombres de m√©todos exactos\n",
        "\n",
        "mis_frases = [\n",
        "    \"el perro ladra\",\n",
        "    \"el gato maulla\",\n",
        "    \"el perro come\"\n",
        "]\n",
        "\n",
        "print(\"üìù Mis frases:\")\n",
        "for frase in mis_frases:\n",
        "    print(f\"   - {frase}\")\n",
        "print()\n",
        "\n",
        "# Crea el vocabulario (palabras √∫nicas)\n",
        "vocabulario = set()\n",
        "for frase in mis_frases:\n",
        "    palabras = frase.split()\n",
        "    vocabulario.update(palabras)\n",
        "\n",
        "vocabulario = sorted(vocabulario)\n",
        "\n",
        "print(\"üìñ Vocabulario encontrado:\")\n",
        "print(f\"   {vocabulario}\")\n",
        "print(f\"   Total de palabras √∫nicas: {len(vocabulario)}\")\n",
        "print()\n",
        "\n",
        "# Convierte la primera frase a vector\n",
        "primera_frase = mis_frases[0]\n",
        "palabras_primera = primera_frase.split()\n",
        "vector_primera = [1 if palabra in palabras_primera else 0 for palabra in vocabulario]\n",
        "\n",
        "print(f\"Vector de '{primera_frase}':\")\n",
        "print(f\"   {vector_primera}\")\n",
        "\n",
        "# DESAF√çO EXTRA: Convierte TODAS las frases a vectores\n",
        "print(\"\\nüéØ DESAF√çO: Vectoriza todas las frases\")\n",
        "vectores_todos = []\n",
        "for frase in mis_frases:\n",
        "    palabras_frase = frase.split()\n",
        "    vector = [1 if palabra in palabras_frase else 0 for palabra in vocabulario]\n",
        "    vectores_todos.append(vector)\n",
        "\n",
        "print(\"Todos los vectores:\")\n",
        "for i, vector in enumerate(vectores_todos, 1):\n",
        "    print(f\"   Frase {i}: {vector}\")"
      ],
      "metadata": {
        "id": "exercise_bow_manual",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5dc46ce-c351-4231-f0c3-023d76e6691f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìù Mis frases:\n",
            "   - el perro ladra\n",
            "   - el gato maulla\n",
            "   - el perro come\n",
            "\n",
            "üìñ Vocabulario encontrado:\n",
            "   ['come', 'el', 'gato', 'ladra', 'maulla', 'perro']\n",
            "   Total de palabras √∫nicas: 6\n",
            "\n",
            "Vector de 'el perro ladra':\n",
            "   [0, 1, 0, 1, 0, 1]\n",
            "\n",
            "üéØ DESAF√çO: Vectoriza todas las frases\n",
            "Todos los vectores:\n",
            "   Frase 1: [0, 1, 0, 1, 0, 1]\n",
            "   Frase 2: [0, 1, 1, 0, 1, 0]\n",
            "   Frase 3: [1, 1, 0, 0, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üõ†Ô∏è PASO 3: CountVectorizer - La herramienta autom√°tica\n",
        "\n",
        "### üìñ Teor√≠a: Automatizar Bag of Words\n",
        "\n",
        "Hacer Bag of Words manualmente es tedioso. **CountVectorizer** lo hace autom√°ticamente:\n",
        "\n",
        "```python\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(frases)\n",
        "```\n",
        "\n",
        "**Ventajas:**\n",
        "- ‚úÖ Crea el vocabulario autom√°ticamente\n",
        "- ‚úÖ Convierte todas las frases de una vez\n",
        "- ‚úÖ Maneja texto complejo (may√∫sculas, puntuaci√≥n)\n",
        "\n",
        "### üß™ EJEMPLO RESUELTO: Usar CountVectorizer"
      ],
      "metadata": {
        "id": "step3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset de ejemplo\n",
        "documentos = [\n",
        "    \"Me encanta este producto\",\n",
        "    \"Este producto es horrible\",\n",
        "    \"Muy satisfecho con la compra\",\n",
        "    \"P√©sima experiencia de compra\",\n",
        "    \"Excelente calidad y precio\"\n",
        "]\n",
        "\n",
        "print(\"üìö DOCUMENTOS ORIGINALES:\")\n",
        "for i, doc in enumerate(documentos, 1):\n",
        "    print(f\"   {i}. {doc}\")\n",
        "print()\n",
        "\n",
        "# Crear y ajustar el vectorizador\n",
        "vectorizador = CountVectorizer()\n",
        "X = vectorizador.fit_transform(documentos)\n",
        "\n",
        "# Explorar el vocabulario\n",
        "vocabulario = vectorizador.vocabulary_\n",
        "print(f\"üìñ VOCABULARIO GENERADO ({len(vocabulario)} palabras):\")\n",
        "for palabra, indice in sorted(vocabulario.items(), key=lambda x: x[1]):\n",
        "    print(f\"   {indice:2d}. '{palabra}'\")\n",
        "print()\n",
        "\n",
        "# Convertir a matriz densa para visualizar\n",
        "X_denso = X.toarray()\n",
        "print(\"üî¢ MATRIZ DE CARACTER√çSTICAS (Bag of Words):\")\n",
        "print(f\"   Forma: {X_denso.shape} (filas=documentos, columnas=palabras)\\n\")\n",
        "\n",
        "# Crear DataFrame para mejor visualizaci√≥n\n",
        "nombres_caracteristicas = vectorizador.get_feature_names_out()\n",
        "df_bow = pd.DataFrame(X_denso, columns=nombres_caracteristicas)\n",
        "print(df_bow)\n",
        "print()\n",
        "\n",
        "print(\"üí° INTERPRETACI√ìN:\")\n",
        "print(\"   - Cada fila = un documento\")\n",
        "print(\"   - Cada columna = una palabra del vocabulario\")\n",
        "print(\"   - Valores = n√∫mero de veces que aparece la palabra\")"
      ],
      "metadata": {
        "id": "example_countvectorizer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ddea8d5-7e9c-42c3-a40f-f5b83c97fd7e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìö DOCUMENTOS ORIGINALES:\n",
            "   1. Me encanta este producto\n",
            "   2. Este producto es horrible\n",
            "   3. Muy satisfecho con la compra\n",
            "   4. P√©sima experiencia de compra\n",
            "   5. Excelente calidad y precio\n",
            "\n",
            "üìñ VOCABULARIO GENERADO (17 palabras):\n",
            "    0. 'calidad'\n",
            "    1. 'compra'\n",
            "    2. 'con'\n",
            "    3. 'de'\n",
            "    4. 'encanta'\n",
            "    5. 'es'\n",
            "    6. 'este'\n",
            "    7. 'excelente'\n",
            "    8. 'experiencia'\n",
            "    9. 'horrible'\n",
            "   10. 'la'\n",
            "   11. 'me'\n",
            "   12. 'muy'\n",
            "   13. 'precio'\n",
            "   14. 'producto'\n",
            "   15. 'p√©sima'\n",
            "   16. 'satisfecho'\n",
            "\n",
            "üî¢ MATRIZ DE CARACTER√çSTICAS (Bag of Words):\n",
            "   Forma: (5, 17) (filas=documentos, columnas=palabras)\n",
            "\n",
            "   calidad  compra  con  de  encanta  es  este  excelente  experiencia  \\\n",
            "0        0       0    0   0        1   0     1          0            0   \n",
            "1        0       0    0   0        0   1     1          0            0   \n",
            "2        0       1    1   0        0   0     0          0            0   \n",
            "3        0       1    0   1        0   0     0          0            1   \n",
            "4        1       0    0   0        0   0     0          1            0   \n",
            "\n",
            "   horrible  la  me  muy  precio  producto  p√©sima  satisfecho  \n",
            "0         0   0   1    0       0         1       0           0  \n",
            "1         1   0   0    0       0         1       0           0  \n",
            "2         0   1   0    1       0         0       0           1  \n",
            "3         0   0   0    0       0         0       1           0  \n",
            "4         0   0   0    0       1         0       0           0  \n",
            "\n",
            "üí° INTERPRETACI√ìN:\n",
            "   - Cada fila = un documento\n",
            "   - Cada columna = una palabra del vocabulario\n",
            "   - Valores = n√∫mero de veces que aparece la palabra\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚úçÔ∏è AHORA T√ö: Usa CountVectorizer\n",
        "\n",
        "**Completa el c√≥digo siguiente:**"
      ],
      "metadata": {
        "id": "exercise3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EJERCICIO 2: Vectoriza tus propias frases\n",
        "#\n",
        "# üí° PISTA GLOBAL:\n",
        "# - CountVectorizer es la clase que necesitas instanciar\n",
        "# - Tiene un m√©todo que ajusta Y transforma en un solo paso (fit_transform)\n",
        "# - El vocabulario es un atributo (termina con _)\n",
        "# - Las matrices dispersas tienen un m√©todo para convertirse en arrays densos\n",
        "# - Usa los atributos .shape para obtener dimensiones (es una tupla)\n",
        "# - Los diccionarios tienen un m√©todo para obtener sus claves\n",
        "\n",
        "mis_documentos = [\n",
        "    \"Python es un lenguaje genial\",\n",
        "    \"Me gusta programar en Python\",\n",
        "    \"El lenguaje Python es f√°cil\",\n",
        "    \"Programar es divertido\"\n",
        "]\n",
        "\n",
        "# Crea el vectorizador\n",
        "mi_vectorizador = CountVectorizer()\n",
        "\n",
        "# Transforma los documentos\n",
        "X_mis_docs = mi_vectorizador.fit_transform(mis_documentos)\n",
        "\n",
        "# Obt√©n el vocabulario\n",
        "mi_vocabulario = mi_vectorizador.vocabulary_\n",
        "print(f\"üìñ Vocabulario ({len(mi_vocabulario)} palabras):\")\n",
        "print(f\"   {sorted(mi_vocabulario.keys())}\")\n",
        "print()\n",
        "\n",
        "# Convierte a matriz densa\n",
        "X_denso = X_mis_docs.toarray()\n",
        "print(f\"üî¢ Forma de la matriz: {X_denso.shape}\")\n",
        "print(f\"   {X_denso.shape[0]} documentos x {X_denso.shape[1]} palabras\")\n",
        "print()\n",
        "\n",
        "# NUEVO: Analiza la primera fila en detalle\n",
        "print(\"üîç An√°lisis del primer documento:\")\n",
        "primera_fila = X_denso[0]\n",
        "print(f\"Vector: {primera_fila}\")\n",
        "palabras_no_cero = sum(primera_fila > 0)\n",
        "print(f\"Palabras diferentes del documento: {palabras_no_cero}\")"
      ],
      "metadata": {
        "id": "exercise_countvectorizer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45a2aa59-f09a-45a8-adb9-1041aa5f51d0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìñ Vocabulario (12 palabras):\n",
            "   ['divertido', 'el', 'en', 'es', 'f√°cil', 'genial', 'gusta', 'lenguaje', 'me', 'programar', 'python', 'un']\n",
            "\n",
            "üî¢ Forma de la matriz: (4, 12)\n",
            "   4 documentos x 12 palabras\n",
            "\n",
            "üîç An√°lisis del primer documento:\n",
            "Vector: [0 0 0 1 0 1 0 1 0 0 1 1]\n",
            "Palabras diferentes del documento: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üîç PASO 4: Explorar la matriz de caracter√≠sticas\n",
        "\n",
        "### üìñ Teor√≠a: Entender qu√© genera CountVectorizer\n",
        "\n",
        "La matriz resultante tiene:\n",
        "- **Filas**: Cada documento/frase\n",
        "- **Columnas**: Cada palabra del vocabulario\n",
        "- **Valores**: Frecuencia de aparici√≥n (por defecto)\n",
        "\n",
        "**Caracter√≠sticas importantes:**\n",
        "- Es una **matriz dispersa** (sparse) ‚Üí muchos ceros\n",
        "- Se puede convertir a **matriz densa** con `.toarray()`\n",
        "- Cada columna es una **caracter√≠stica** para el modelo\n",
        "\n",
        "### üß™ EJEMPLO RESUELTO: An√°lisis detallado"
      ],
      "metadata": {
        "id": "step4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un dataset m√°s completo\n",
        "textos = [\n",
        "    \"El caf√© est√° muy caliente\",\n",
        "    \"Me gusta el caf√© caliente\",\n",
        "    \"El t√© est√° fr√≠o\",\n",
        "    \"Prefiero el t√© caliente\",\n",
        "    \"No me gusta el t√© fr√≠o\"\n",
        "]\n",
        "\n",
        "# Vectorizar\n",
        "vec = CountVectorizer()\n",
        "X = vec.fit_transform(textos)\n",
        "\n",
        "print(\"üîç AN√ÅLISIS DETALLADO DE LA MATRIZ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Informaci√≥n b√°sica\n",
        "print(f\"\\nüìä Dimensiones de la matriz:\")\n",
        "print(f\"   Documentos (filas): {X.shape[0]}\")\n",
        "print(f\"   Palabras (columnas): {X.shape[1]}\")\n",
        "print(f\"   Total de elementos: {X.shape[0] * X.shape[1]}\")\n",
        "print(f\"   Elementos no-cero: {X.nnz}\")\n",
        "print(f\"   Densidad: {X.nnz / (X.shape[0] * X.shape[1]) * 100:.1f}%\")\n",
        "print()\n",
        "\n",
        "# Palabras m√°s frecuentes\n",
        "X_denso = X.toarray()\n",
        "frecuencias = X_denso.sum(axis=0)\n",
        "palabras = vec.get_feature_names_out()\n",
        "\n",
        "print(\"üìà PALABRAS M√ÅS FRECUENTES:\")\n",
        "palabras_frecuentes = sorted(zip(palabras, frecuencias), key=lambda x: x[1], reverse=True)\n",
        "for palabra, freq in palabras_frecuentes[:5]:\n",
        "    print(f\"   '{palabra}': aparece {int(freq)} veces\")\n",
        "print()\n",
        "\n",
        "# Ejemplo de un documento espec√≠fico\n",
        "doc_idx = 1\n",
        "print(f\"üéØ AN√ÅLISIS DEL DOCUMENTO {doc_idx + 1}: '{textos[doc_idx]}'\")\n",
        "print(f\"   Vector completo: {X_denso[doc_idx]}\")\n",
        "print(f\"   Palabras presentes:\")\n",
        "for i, val in enumerate(X_denso[doc_idx]):\n",
        "    if val > 0:\n",
        "        print(f\"      - '{palabras[i]}': {int(val)} vez/veces\")"
      ],
      "metadata": {
        "id": "example_matrix_analysis",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6902b37f-f3eb-4a27-9bbc-2ce80b2fcd2c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç AN√ÅLISIS DETALLADO DE LA MATRIZ\n",
            "============================================================\n",
            "\n",
            "üìä Dimensiones de la matriz:\n",
            "   Documentos (filas): 5\n",
            "   Palabras (columnas): 11\n",
            "   Total de elementos: 55\n",
            "   Elementos no-cero: 24\n",
            "   Densidad: 43.6%\n",
            "\n",
            "üìà PALABRAS M√ÅS FRECUENTES:\n",
            "   'el': aparece 5 veces\n",
            "   'caliente': aparece 3 veces\n",
            "   't√©': aparece 3 veces\n",
            "   'caf√©': aparece 2 veces\n",
            "   'est√°': aparece 2 veces\n",
            "\n",
            "üéØ AN√ÅLISIS DEL DOCUMENTO 2: 'Me gusta el caf√© caliente'\n",
            "   Vector completo: [1 1 1 0 0 1 1 0 0 0 0]\n",
            "   Palabras presentes:\n",
            "      - 'caf√©': 1 vez/veces\n",
            "      - 'caliente': 1 vez/veces\n",
            "      - 'el': 1 vez/veces\n",
            "      - 'gusta': 1 vez/veces\n",
            "      - 'me': 1 vez/veces\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚úçÔ∏è AHORA T√ö: Analiza una matriz\n",
        "\n",
        "**Completa el c√≥digo siguiente:**"
      ],
      "metadata": {
        "id": "exercise4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EJERCICIO 3: Analiza un dataset de opiniones\n",
        "#\n",
        "# üí° PISTA GLOBAL:\n",
        "# - .shape es una tupla: primer elemento son filas, segundo son columnas\n",
        "# - Para sumar por columnas, axis=0; para sumar por filas, axis=1\n",
        "# - argmax() devuelve el √≠ndice del valor m√°ximo\n",
        "# - Puedes usar √≠ndices para acceder a elementos de arrays y listas\n",
        "# - NumPy tiene funciones para ordenar arrays: argsort devuelve √≠ndices ordenados\n",
        "# - Usa slicing negativo para obtener los √∫ltimos elementos y [::-1] para invertir\n",
        "\n",
        "opiniones = [\n",
        "    \"La pel√≠cula es excelente\",\n",
        "    \"No me gust√≥ la pel√≠cula\",\n",
        "    \"La actuaci√≥n es buena\",\n",
        "    \"La pel√≠cula es aburrida\",\n",
        "    \"Excelente actuaci√≥n y gui√≥n\"\n",
        "]\n",
        "\n",
        "# Vectoriza\n",
        "vec_opiniones = CountVectorizer()\n",
        "X_opiniones = vec_opiniones.fit_transform(opiniones)\n",
        "\n",
        "# COMPLETA: Obt√©n las dimensiones\n",
        "num_docs = X_opiniones.shape[0]\n",
        "num_palabras = X_opiniones.shape[1]\n",
        "\n",
        "print(f\"üìä La matriz tiene:\")\n",
        "print(f\"   {num_docs} opiniones\")\n",
        "print(f\"   {num_palabras} palabras √∫nicas\")\n",
        "print()\n",
        "\n",
        "# COMPLETA: Encuentra la palabra m√°s frecuente\n",
        "X_denso = X_opiniones.toarray()\n",
        "frecuencias = X_denso.sum(axis=0)\n",
        "palabras = vec_opiniones.get_feature_names_out()\n",
        "\n",
        "# Encuentra el √≠ndice de la palabra m√°s frecuente\n",
        "idx_max = frecuencias.argmax()\n",
        "palabra_mas_frecuente = palabras[idx_max]\n",
        "frecuencia_max = frecuencias[idx_max]\n",
        "\n",
        "print(f\"üèÜ Palabra m√°s frecuente: '{palabra_mas_frecuente}'\")\n",
        "print(f\"   Aparece {int(frecuencia_max)} veces\")\n",
        "print()\n",
        "\n",
        "# NUEVO DESAF√çO: Encuentra las 3 palabras M√ÅS frecuentes\n",
        "print(\"üéØ DESAF√çO: Top 3 palabras m√°s frecuentes\")\n",
        "indices_ordenados = np.argsort(frecuencias)[-3:][::-1]\n",
        "print(\"Top 3 palabras:\")\n",
        "for i, idx in enumerate(indices_ordenados, 1):\n",
        "    print(f\"   {i}. '{palabras[idx]}' - {int(frecuencias[idx])} veces\")"
      ],
      "metadata": {
        "id": "exercise_matrix_analysis",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa87e597-3845-4b0c-e638-ff98ce8c5f0c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä La matriz tiene:\n",
            "   5 opiniones\n",
            "   11 palabras √∫nicas\n",
            "\n",
            "üèÜ Palabra m√°s frecuente: 'la'\n",
            "   Aparece 4 veces\n",
            "\n",
            "üéØ DESAF√çO: Top 3 palabras m√°s frecuentes\n",
            "Top 3 palabras:\n",
            "   1. 'la' - 4 veces\n",
            "   2. 'es' - 3 veces\n",
            "   3. 'pel√≠cula' - 3 veces\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLjO0iP1yS5W"
      },
      "source": [
        "### üöÄ NUEVO EJERCICIO: Funci√≥n de Vectorizaci√≥n Completa\n",
        "\n",
        "Antes de continuar, vamos a crear una **funci√≥n reutilizable** que encapsule todo el proceso de vectorizaci√≥n.\n",
        "\n",
        "**Tu misi√≥n:** Crear una funci√≥n que reciba textos y devuelva la matriz vectorizada Y el vocabulario.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZlz5LroyS5W",
        "outputId": "faa1b505-4451-400a-cf5c-21d6c648810f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Funci√≥n ejecutada correctamente\n",
            "üìä Matriz generada: (3, 9)\n",
            "üìñ Vocabulario: 9 palabras\n",
            "\n",
            "Primeras palabras: ['me', 'gusta', 'el', 'caf√©', 'no']\n"
          ]
        }
      ],
      "source": [
        "# EJERCICIO 3.5: Crea una funci√≥n de vectorizaci√≥n completa\n",
        "#\n",
        "# üí° PISTA GLOBAL:\n",
        "# - La funci√≥n debe recibir una lista de textos\n",
        "# - Debe crear un vectorizador, ajustarlo, y transformar los textos\n",
        "# - Debe devolver DOS cosas: la matriz (como array denso) y el diccionario de vocabulario\n",
        "# - Usa la sintaxis 'return valor1, valor2' para devolver m√∫ltiples valores\n",
        "# - No olvides convertir a .toarray() para la matriz\n",
        "\n",
        "def vectorizar_textos(textos):\n",
        "    \"\"\"\n",
        "    Vectoriza una lista de textos usando CountVectorizer.\n",
        "\n",
        "    Args:\n",
        "        textos (list): Lista de strings a vectorizar\n",
        "\n",
        "    Returns:\n",
        "        tuple: (matriz_vectorizada, vocabulario_dict)\n",
        "    \"\"\"\n",
        "    # Crea el vectorizador\n",
        "    vec = CountVectorizer()\n",
        "\n",
        "    # Ajusta y transforma los textos\n",
        "    matriz = vec.fit_transform(textos).toarray()\n",
        "\n",
        "    # Obt√©n el vocabulario\n",
        "    vocabulario = vec.vocabulary_\n",
        "\n",
        "    # Devuelve ambos\n",
        "    return matriz, vocabulario\n",
        "\n",
        "# Prueba tu funci√≥n\n",
        "textos_prueba = [\n",
        "    \"Me gusta el caf√©\",\n",
        "    \"No me gusta el t√©\",\n",
        "    \"El caf√© es mejor que el t√©\"\n",
        "]\n",
        "\n",
        "X, vocab = vectorizar_textos(textos_prueba)\n",
        "\n",
        "print(f\"‚úÖ Funci√≥n ejecutada correctamente\")\n",
        "print(f\"üìä Matriz generada: {X.shape}\")\n",
        "print(f\"üìñ Vocabulario: {len(vocab)} palabras\")\n",
        "print(f\"\\nPrimeras palabras: {list(vocab.keys())[0:5]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## ‚úÇÔ∏è PASO 5: Dividir datos con train_test_split\n",
        "\n",
        "### üìñ Teor√≠a: ¬øPor qu√© dividir los datos?\n",
        "\n",
        "En Machine Learning, dividimos los datos en:\n",
        "\n",
        "1. **Entrenamiento (Train)**: 70-80% de los datos\n",
        "   - Para que el modelo **aprenda**\n",
        "\n",
        "2. **Test (Prueba)**: 20-30% de los datos\n",
        "   - Para **evaluar** el rendimiento real\n",
        "   - El modelo NUNCA ve estos datos durante el entrenamiento\n",
        "\n",
        "**¬øPor qu√© es importante?**\n",
        "- Evita el **overfitting** (memorizaci√≥n)\n",
        "- Mide la **generalizaci√≥n** del modelo\n",
        "- Simula datos nuevos que el modelo ver√° en producci√≥n\n",
        "\n",
        "### üß™ EJEMPLO RESUELTO: train_test_split"
      ],
      "metadata": {
        "id": "step5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset de ejemplo\n",
        "frases = [\n",
        "    \"Me encanta este producto\",\n",
        "    \"Excelente calidad\",\n",
        "    \"Muy satisfecho\",\n",
        "    \"Perfecto\",\n",
        "    \"Lo recomiendo\",\n",
        "    \"Muy decepcionado\",\n",
        "    \"Mala calidad\",\n",
        "    \"No lo recomiendo\",\n",
        "    \"P√©sima experiencia\",\n",
        "    \"No cumple lo prometido\"\n",
        "]\n",
        "\n",
        "# Etiquetas: 1=positivo, 0=negativo\n",
        "etiquetas = [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
        "\n",
        "print(\"üìö DATASET ORIGINAL:\")\n",
        "print(f\"   Total de frases: {len(frases)}\")\n",
        "print(f\"   Positivas: {sum(etiquetas)}\")\n",
        "print(f\"   Negativas: {len(etiquetas) - sum(etiquetas)}\")\n",
        "print()\n",
        "\n",
        "# Vectorizar ANTES de dividir\n",
        "vectorizador = CountVectorizer()\n",
        "X = vectorizador.fit_transform(frases).toarray()\n",
        "y = np.array(etiquetas)\n",
        "\n",
        "print(f\"üî¢ Matriz de caracter√≠sticas: {X.shape}\")\n",
        "print()\n",
        "\n",
        "# Dividir en train y test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.3,  # 30% para test\n",
        "    random_state=42,  # Para reproducibilidad\n",
        "    stratify=y  # Mantener la proporci√≥n de clases\n",
        ")\n",
        "\n",
        "print(\"‚úÇÔ∏è DATOS DIVIDIDOS:\")\n",
        "print(f\"   Entrenamiento: {X_train.shape[0]} frases ({X_train.shape[0]/len(frases)*100:.0f}%)\")\n",
        "print(f\"      - Positivas: {sum(y_train)}\")\n",
        "print(f\"      - Negativas: {len(y_train) - sum(y_train)}\")\n",
        "print()\n",
        "print(f\"   Test: {X_test.shape[0]} frases ({X_test.shape[0]/len(frases)*100:.0f}%)\")\n",
        "print(f\"      - Positivas: {sum(y_test)}\")\n",
        "print(f\"      - Negativas: {len(y_test) - sum(y_test)}\")\n",
        "print()\n",
        "\n",
        "print(\"üí° IMPORTANTE:\")\n",
        "print(\"   - El modelo se entrena SOLO con X_train e y_train\")\n",
        "print(\"   - X_test e y_test se usan SOLO para evaluar al final\")\n",
        "print(\"   - NUNCA mezcles train y test durante el entrenamiento\")"
      ],
      "metadata": {
        "id": "example_train_test_split",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b374cfd9-14dc-40a1-e167-a83896601d77"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìö DATASET ORIGINAL:\n",
            "   Total de frases: 10\n",
            "   Positivas: 5\n",
            "   Negativas: 5\n",
            "\n",
            "üî¢ Matriz de caracter√≠sticas: (10, 18)\n",
            "\n",
            "‚úÇÔ∏è DATOS DIVIDIDOS:\n",
            "   Entrenamiento: 7 frases (70%)\n",
            "      - Positivas: 4\n",
            "      - Negativas: 3\n",
            "\n",
            "   Test: 3 frases (30%)\n",
            "      - Positivas: 1\n",
            "      - Negativas: 2\n",
            "\n",
            "üí° IMPORTANTE:\n",
            "   - El modelo se entrena SOLO con X_train e y_train\n",
            "   - X_test e y_test se usan SOLO para evaluar al final\n",
            "   - NUNCA mezcles train y test durante el entrenamiento\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚úçÔ∏è AHORA T√ö: Divide tus datos\n",
        "\n",
        "**Completa el c√≥digo siguiente:**"
      ],
      "metadata": {
        "id": "exercise5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EJERCICIO 4: Prepara datos para un clasificador\n",
        "#\n",
        "# üí° PISTA GLOBAL:\n",
        "# - Primero vectoriza con CountVectorizer (instanciar, fit_transform, toarray)\n",
        "# - Convierte etiquetas a numpy array con np.array()\n",
        "# - train_test_split necesita: X, y, test_size, random_state, stratify\n",
        "# - El par√°metro stratify debe ser las etiquetas originales (y) para mantener balance\n",
        "# - test_size=0.2 significa 20% para test\n",
        "# - Para calcular balance: usa sum() y operaciones aritm√©ticas con len()\n",
        "\n",
        "textos = [\n",
        "    \"Me gusta Python\", \"Python es genial\", \"Aprendo Python\",\n",
        "    \"No me gusta Java\", \"Java es complicado\", \"Dif√≠cil aprender Java\",\n",
        "    \"Python es f√°cil\", \"Programar en Python\",\n",
        "    \"Java es aburrido\", \"No entiendo Java\"\n",
        "]\n",
        "etiquetas = [1, 1, 1, 0, 0, 0, 1, 1, 0, 0]  # 1=Python (positivo), 0=Java (negativo)\n",
        "\n",
        "# COMPLETA: Vectoriza los textos\n",
        "vec = CountVectorizer()\n",
        "X = vec.fit_transform(textos).toarray()\n",
        "y = np.array(etiquetas)\n",
        "\n",
        "print(f\"üìä Total de datos: {len(textos)}\")\n",
        "print(f\"üî¢ Tama√±o de la matriz: {X.shape}\")\n",
        "print()\n",
        "\n",
        "# COMPLETA: Divide en train (80%) y test (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"‚úÇÔ∏è DIVISI√ìN COMPLETADA:\")\n",
        "print(f\"   Entrenamiento: {X_train.shape[0]} ejemplos\")\n",
        "print(f\"   Test: {X_test.shape[0]} ejemplos\")\n",
        "print()\n",
        "\n",
        "# Verifica el balance\n",
        "pos_train = sum(y_train)\n",
        "pos_test = sum(y_test)\n",
        "print(f\"‚úÖ Train: {pos_train} positivos, {len(y_train) - pos_train} negativos\")\n",
        "print(f\"‚úÖ Test: {pos_test} positivos, {len(y_test) - pos_test} negativos\")\n",
        "\n",
        "# NUEVO: Calcula el porcentaje de balance\n",
        "print(\"\\nüìä An√°lisis de balance:\")\n",
        "balance_train = pos_train / len(y_train)\n",
        "balance_test = pos_test / len(y_test)\n",
        "print(f\"   Train: {balance_train*100:.1f}% positivos\")\n",
        "print(f\"   Test: {balance_test*100:.1f}% positivos\")"
      ],
      "metadata": {
        "id": "exercise_train_test_split",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a8ebed5-563f-42b5-928d-5fc8b925156b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Total de datos: 10\n",
            "üî¢ Tama√±o de la matriz: (10, 16)\n",
            "\n",
            "‚úÇÔ∏è DIVISI√ìN COMPLETADA:\n",
            "   Entrenamiento: 8 ejemplos\n",
            "   Test: 2 ejemplos\n",
            "\n",
            "‚úÖ Train: 4 positivos, 4 negativos\n",
            "‚úÖ Test: 1 positivos, 1 negativos\n",
            "\n",
            "üìä An√°lisis de balance:\n",
            "   Train: 50.0% positivos\n",
            "   Test: 50.0% positivos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üéØ MINI-PROYECTO FINAL: Preparar Dataset de Sentimientos\n",
        "\n",
        "Ahora vamos a preparar **todo el pipeline** completo de procesamiento de texto para el proyecto final.\n",
        "\n",
        "### üìã Objetivo:\n",
        "1. Crear un dataset de sentimientos balanceado\n",
        "2. Vectorizar el texto con CountVectorizer\n",
        "3. Dividir en train/test correctamente\n",
        "4. Verificar que todo est√° listo para entrenar\n",
        "\n",
        "### ‚úçÔ∏è COMPLETA EL PROYECTO:"
      ],
      "metadata": {
        "id": "final_project"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PASO 1: Crear el dataset completo\n",
        "frases_positivas = [\n",
        "    \"Me encanta este producto\",\n",
        "    \"Excelente calidad\",\n",
        "    \"Muy satisfecho con la compra\",\n",
        "    \"Super√≥ mis expectativas\",\n",
        "    \"Lo recomiendo totalmente\",\n",
        "    \"Perfecto justo lo que buscaba\",\n",
        "    \"Incre√≠ble experiencia\",\n",
        "    \"Volver√© a comprar sin duda\",\n",
        "    \"Calidad precio excelente\",\n",
        "    \"Estoy muy feliz con esto\",\n",
        "    \"Fant√°stico producto\",\n",
        "    \"Mejor de lo esperado\",\n",
        "    \"Totalmente recomendable\",\n",
        "    \"Me ha encantado\",\n",
        "    \"Producto de alta calidad\"\n",
        "]\n",
        "\n",
        "frases_negativas = [\n",
        "    \"Muy decepcionado\",\n",
        "    \"Mala calidad\",\n",
        "    \"No lo recomiendo\",\n",
        "    \"P√©sima experiencia\",\n",
        "    \"No cumple lo prometido\",\n",
        "    \"P√©rdida de dinero\",\n",
        "    \"Terrible servicio\",\n",
        "    \"No volver√≠a a comprar\",\n",
        "    \"Muy por debajo de lo esperado\",\n",
        "    \"Completamente insatisfecho\",\n",
        "    \"Producto defectuoso\",\n",
        "    \"Mal√≠sima compra\",\n",
        "    \"No funciona bien\",\n",
        "    \"Decepcionante y caro\",\n",
        "    \"No vale la pena\"\n",
        "]\n",
        "\n",
        "# Combinar todo\n",
        "frases = frases_positivas + frases_negativas\n",
        "etiquetas = [1] * len(frases_positivas) + [0] * len(frases_negativas)\n",
        "\n",
        "print(\"üìä DATASET CREADO\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total de frases: {len(frases)}\")\n",
        "print(f\"Frases positivas: {sum(etiquetas)}\")\n",
        "print(f\"Frases negativas: {len(etiquetas) - sum(etiquetas)}\")\n",
        "print(f\"Dataset balanceado: {'‚úÖ S√ç' if sum(etiquetas) == len(etiquetas) - sum(etiquetas) else '‚ùå NO'}\")\n",
        "print()\n",
        "\n",
        "# Mostrar ejemplos\n",
        "print(\"üìù EJEMPLOS:\")\n",
        "print(\"Positivas:\")\n",
        "for frase in frases_positivas[:3]:\n",
        "    print(f\"   + {frase}\")\n",
        "print(\"Negativas:\")\n",
        "for frase in frases_negativas[:3]:\n",
        "    print(f\"   - {frase}\")"
      ],
      "metadata": {
        "id": "project_step1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06a9c88d-7223-4760-9d70-6f09ecd1a873"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä DATASET CREADO\n",
            "============================================================\n",
            "Total de frases: 30\n",
            "Frases positivas: 15\n",
            "Frases negativas: 15\n",
            "Dataset balanceado: ‚úÖ S√ç\n",
            "\n",
            "üìù EJEMPLOS:\n",
            "Positivas:\n",
            "   + Me encanta este producto\n",
            "   + Excelente calidad\n",
            "   + Muy satisfecho con la compra\n",
            "Negativas:\n",
            "   - Muy decepcionado\n",
            "   - Mala calidad\n",
            "   - No lo recomiendo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PASO 2: Vectorizar el texto\n",
        "print(\"\\nüî§ VECTORIZANDO TEXTO\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# EJERCICIO 5: Crea y aplica el vectorizador\n",
        "#\n",
        "# üí° PISTA: Usa CountVectorizer, fit_transform y toarray en una cadena\n",
        "# Recuerda: el vocabulario es un atributo que termina con gui√≥n bajo\n",
        "# Usa sorted() para ordenar las claves del vocabulario\n",
        "\n",
        "vectorizador = CountVectorizer()\n",
        "X = vectorizador.fit_transform(frases).toarray()\n",
        "y = np.array(etiquetas)\n",
        "\n",
        "print(f\"‚úÖ Vectorizaci√≥n completada\")\n",
        "print(f\"Forma de X: {X.shape}\")\n",
        "print(f\"   - {X.shape[0]} documentos\")\n",
        "print(f\"   - {X.shape[1]} caracter√≠sticas (palabras √∫nicas)\")\n",
        "print()\n",
        "\n",
        "# Explorar el vocabulario\n",
        "vocabulario = vectorizador.vocabulary_\n",
        "print(f\"üìñ Vocabulario: {len(vocabulario)} palabras √∫nicas\")\n",
        "palabras_ordenadas = sorted(vocabulario.keys())\n",
        "print(f\"Primeras 10 palabras: {palabras_ordenadas[:10]}\")"
      ],
      "metadata": {
        "id": "project_step2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "284b9827-472c-46ad-892d-a13d19d0706a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üî§ VECTORIZANDO TEXTO\n",
            "============================================================\n",
            "‚úÖ Vectorizaci√≥n completada\n",
            "Forma de X: (30, 62)\n",
            "   - 30 documentos\n",
            "   - 62 caracter√≠sticas (palabras √∫nicas)\n",
            "\n",
            "üìñ Vocabulario: 62 palabras √∫nicas\n",
            "Primeras 10 palabras: ['alta', 'bien', 'buscaba', 'calidad', 'caro', 'completamente', 'compra', 'comprar', 'con', 'cumple']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PASO 3: Dividir en train y test\n",
        "print(\"\\n‚úÇÔ∏è DIVIDIENDO DATOS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# EJERCICIO 6: Divide los datos (20% para test)\n",
        "#\n",
        "# üí° PISTA: train_test_split(X, y, test_size=?, random_state=?, stratify=?)\n",
        "# Revisa la secci√≥n anterior si necesitas recordar los nombres exactos de los par√°metros\n",
        "# Para los c√°lculos de porcentaje: usa divisi√≥n (/) y multiplicaci√≥n (*) con 100\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Divisi√≥n completada\")\n",
        "print()\n",
        "print(\"üìä CONJUNTO DE ENTRENAMIENTO:\")\n",
        "print(f\"   Tama√±o: {X_train.shape[0]} frases ({X_train.shape[0]/len(frases)*100:.0f}%)\")\n",
        "print(f\"   Positivas: {sum(y_train)} ({sum(y_train)/len(y_train)*100:.1f}%)\")\n",
        "print(f\"   Negativas: {len(y_train) - sum(y_train)} ({(len(y_train) - sum(y_train))/len(y_train)*100:.1f}%)\")\n",
        "print()\n",
        "print(\"üìä CONJUNTO DE TEST:\")\n",
        "print(f\"   Tama√±o: {X_test.shape[0]} frases ({X_test.shape[0]/len(frases)*100:.0f}%)\")\n",
        "print(f\"   Positivas: {sum(y_test)} ({sum(y_test)/len(y_test)*100:.1f}%)\")\n",
        "print(f\"   Negativas: {len(y_test) - sum(y_test)} ({(len(y_test) - sum(y_test))/len(y_test)*100:.1f}%)\")"
      ],
      "metadata": {
        "id": "project_step3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff0194fb-1095-46c3-e304-346275c105b5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÇÔ∏è DIVIDIENDO DATOS\n",
            "============================================================\n",
            "‚úÖ Divisi√≥n completada\n",
            "\n",
            "üìä CONJUNTO DE ENTRENAMIENTO:\n",
            "   Tama√±o: 24 frases (80%)\n",
            "   Positivas: 12 (50.0%)\n",
            "   Negativas: 12 (50.0%)\n",
            "\n",
            "üìä CONJUNTO DE TEST:\n",
            "   Tama√±o: 6 frases (20%)\n",
            "   Positivas: 3 (50.0%)\n",
            "   Negativas: 3 (50.0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nSDpYpoyS5Z"
      },
      "source": [
        "---\n",
        "\n",
        "## üèÜ EJERCICIO FINAL: Pipeline Completo de Procesamiento\n",
        "\n",
        "### üéØ Tu Misi√≥n Final\n",
        "\n",
        "Crea una funci√≥n **COMPLETA** que:\n",
        "1. Reciba textos y etiquetas\n",
        "2. Vectorice los textos\n",
        "3. Divida en train/test\n",
        "4. Devuelva todo lo necesario para entrenar un modelo\n",
        "\n",
        "**Esta funci√≥n debe encapsular TODO el pipeline de preprocesamiento.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvWduGwnyS5Z",
        "outputId": "bbd0333e-0397-4cc3-c1fd-34b3c8cb75bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéâ ¬°FUNCI√ìN EJECUTADA CORRECTAMENTE!\n",
            "============================================================\n",
            "\n",
            "üìä RESULTADOS:\n",
            "   X_train: (7, 16)\n",
            "   X_test: (3, 16)\n",
            "   y_train: 7 ejemplos\n",
            "   y_test: 3 ejemplos\n",
            "   Vocabulario: 16 palabras\n",
            "\n",
            "üß™ PRUEBA CON FRASE NUEVA:\n",
            "   Frase: 'Este producto es fant√°stico'\n",
            "   Vector: forma (1, 16)\n",
            "   ‚úÖ ¬°Lista para clasificar!\n"
          ]
        }
      ],
      "source": [
        "# üèÜ EJERCICIO FINAL: Funci√≥n de Pipeline Completo\n",
        "#\n",
        "# üí° PISTAS GLOBALES:\n",
        "# 1. La funci√≥n debe recibir: textos (list), etiquetas (list), test_size (float, default=0.2)\n",
        "# 2. Internamente debe: crear vectorizador, fit_transform, convertir etiquetas a array, split\n",
        "# 3. Debe devolver: X_train, X_test, y_train, y_test, vectorizador (¬°5 valores!)\n",
        "# 4. El vectorizador se devuelve para poder transformar datos nuevos despu√©s\n",
        "# 5. Recuerda usar stratify=y en train_test_split\n",
        "#\n",
        "# ESTRUCTURA SUGERIDA:\n",
        "# def procesar_dataset_completo(textos, etiquetas, test_size=0.2):\n",
        "#     # Paso 1: Vectorizar\n",
        "#     vec = ...\n",
        "#     X = ...\n",
        "#     y = ...\n",
        "#\n",
        "#     # Paso 2: Dividir\n",
        "#     X_train, X_test, y_train, y_test = ...\n",
        "#\n",
        "#     # Paso 3: Devolver todo\n",
        "#     return ...\n",
        "\n",
        "def procesar_dataset_completo(textos, etiquetas, test_size=0.2):\n",
        "    \"\"\"\n",
        "    Pipeline completo de procesamiento de texto para ML.\n",
        "\n",
        "    Args:\n",
        "        textos: Lista de strings\n",
        "        etiquetas: Lista de labels (0 o 1)\n",
        "        test_size: Proporci√≥n para test (default 0.2)\n",
        "\n",
        "    Returns:\n",
        "        tuple: (X_train, X_test, y_train, y_test, vectorizador)\n",
        "    \"\"\"\n",
        "    # PASO 1: Vectorizar textos\n",
        "    vec = CountVectorizer()\n",
        "    X = vec.fit_transform(textos).toarray()\n",
        "    y = np.array(etiquetas)\n",
        "\n",
        "    # PASO 2: Dividir en train y test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y,\n",
        "        test_size=test_size,\n",
        "        random_state=42,\n",
        "        stratify=y\n",
        "    )\n",
        "\n",
        "    # PASO 3: Devolver todo (¬°5 valores!)\n",
        "    return X_train, X_test, y_train, y_test, vec\n",
        "\n",
        "\n",
        "# ========== PRUEBA TU FUNCI√ìN ==========\n",
        "\n",
        "# Dataset de prueba\n",
        "textos_prueba = [\n",
        "    \"Excelente producto\", \"Me encanta\", \"Muy bueno\",\n",
        "    \"Horrible\", \"No lo recomiendo\", \"Muy malo\",\n",
        "    \"Perfecto\", \"Gran calidad\",\n",
        "    \"P√©simo\", \"Decepcionante\"\n",
        "]\n",
        "etiquetas_prueba = [1, 1, 1, 0, 0, 0, 1, 1, 0, 0]\n",
        "\n",
        "# Llama a tu funci√≥n\n",
        "X_train, X_test, y_train, y_test, vectorizador = procesar_dataset_completo(\n",
        "    textos_prueba,\n",
        "    etiquetas_prueba,\n",
        "    test_size=0.3\n",
        ")\n",
        "\n",
        "# Verifica los resultados\n",
        "print(\"üéâ ¬°FUNCI√ìN EJECUTADA CORRECTAMENTE!\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nüìä RESULTADOS:\")\n",
        "print(f\"   X_train: {X_train.shape}\")\n",
        "print(f\"   X_test: {X_test.shape}\")\n",
        "print(f\"   y_train: {len(y_train)} ejemplos\")\n",
        "print(f\"   y_test: {len(y_test)} ejemplos\")\n",
        "print(f\"   Vocabulario: {len(vectorizador.vocabulary_)} palabras\")\n",
        "\n",
        "# Prueba con una frase nueva\n",
        "print(\"\\nüß™ PRUEBA CON FRASE NUEVA:\")\n",
        "frase_nueva = [\"Este producto es fant√°stico\"]\n",
        "X_nueva = vectorizador.transform(frase_nueva).toarray()\n",
        "print(f\"   Frase: '{frase_nueva[0]}'\")\n",
        "print(f\"   Vector: forma {X_nueva.shape}\")\n",
        "print(\"   ‚úÖ ¬°Lista para clasificar!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PASO 4: Verificaci√≥n final\n",
        "print(\"\\n‚úÖ VERIFICACI√ìN FINAL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Verificar formas\n",
        "assert X_train.shape[1] == X_test.shape[1], \"‚ùå ERROR: Train y test tienen diferente n√∫mero de caracter√≠sticas\"\n",
        "print(\"‚úÖ Train y test tienen el mismo n√∫mero de caracter√≠sticas\")\n",
        "\n",
        "# Verificar que no hay datos vac√≠os\n",
        "assert X_train.shape[0] > 0 and X_test.shape[0] > 0, \"‚ùå ERROR: Conjuntos vac√≠os\"\n",
        "print(\"‚úÖ Ambos conjuntos contienen datos\")\n",
        "\n",
        "# Verificar balance\n",
        "balance_train = abs(sum(y_train) - (len(y_train) - sum(y_train)))\n",
        "balance_test = abs(sum(y_test) - (len(y_test) - sum(y_test)))\n",
        "print(f\"‚úÖ Balance train: diferencia de {balance_train} ejemplos\")\n",
        "print(f\"‚úÖ Balance test: diferencia de {balance_test} ejemplos\")\n",
        "\n",
        "print()\n",
        "print(\"üéâ ¬°TODO LISTO PARA ENTRENAR UN MODELO!\")\n",
        "print()\n",
        "print(\"üì¶ VARIABLES DISPONIBLES:\")\n",
        "print(\"   - X_train: matriz de entrenamiento\")\n",
        "print(\"   - y_train: etiquetas de entrenamiento\")\n",
        "print(\"   - X_test: matriz de prueba\")\n",
        "print(\"   - y_test: etiquetas de prueba\")\n",
        "print(\"   - vectorizador: para transformar nuevas frases\")"
      ],
      "metadata": {
        "id": "project_step4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "714f3f17-2892-42e8-aa5f-5d581cf68935"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ VERIFICACI√ìN FINAL\n",
            "============================================================\n",
            "‚úÖ Train y test tienen el mismo n√∫mero de caracter√≠sticas\n",
            "‚úÖ Ambos conjuntos contienen datos\n",
            "‚úÖ Balance train: diferencia de 1 ejemplos\n",
            "‚úÖ Balance test: diferencia de 1 ejemplos\n",
            "\n",
            "üéâ ¬°TODO LISTO PARA ENTRENAR UN MODELO!\n",
            "\n",
            "üì¶ VARIABLES DISPONIBLES:\n",
            "   - X_train: matriz de entrenamiento\n",
            "   - y_train: etiquetas de entrenamiento\n",
            "   - X_test: matriz de prueba\n",
            "   - y_test: etiquetas de prueba\n",
            "   - vectorizador: para transformar nuevas frases\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BONUS: Probar el vectorizador con una frase nueva\n",
        "print(\"\\nüß™ PRUEBA CON FRASE NUEVA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "frase_nueva = [\"Este producto es fant√°stico y muy bueno\"]\n",
        "X_nueva = vectorizador.transform(frase_nueva).toarray()\n",
        "\n",
        "print(f\"Frase: '{frase_nueva[0]}'\")\n",
        "print(f\"Vector generado: forma {X_nueva.shape}\")\n",
        "print(f\"Palabras detectadas:\")\n",
        "\n",
        "palabras_presentes = []\n",
        "nombres_caracteristicas = vectorizador.get_feature_names_out()\n",
        "for i, val in enumerate(X_nueva[0]):\n",
        "    if val > 0:\n",
        "        palabras_presentes.append(nombres_caracteristicas[i])\n",
        "\n",
        "print(f\"   {palabras_presentes}\")\n",
        "print()\n",
        "print(\"üí° NOTA: Esta frase est√° lista para ser clasificada por el modelo\")"
      ],
      "metadata": {
        "id": "project_bonus",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db5819f7-528f-4426-a57a-1a98a7bd5364"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß™ PRUEBA CON FRASE NUEVA\n",
            "============================================================\n",
            "Frase: 'Este producto es fant√°stico y muy bueno'\n",
            "Vector generado: forma (1, 16)\n",
            "Palabras detectadas:\n",
            "   ['bueno', 'muy', 'producto']\n",
            "\n",
            "üí° NOTA: Esta frase est√° lista para ser clasificada por el modelo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üéì RESUMEN: ¬øQu√© has aprendido?\n",
        "\n",
        "### ‚úÖ Conceptos clave:\n",
        "\n",
        "| Concepto | Qu√© es | Ejemplo |\n",
        "|----------|--------|--------|\n",
        "| **Bag of Words** | Representar texto como vectores | `[1, 0, 1, 1, 0]` |\n",
        "| **CountVectorizer** | Herramienta para vectorizar texto | `CountVectorizer()` |\n",
        "| **Vocabulario** | Palabras √∫nicas del corpus | `{'me': 0, 'gusta': 1}` |\n",
        "| **Matriz dispersa** | Muchos ceros (eficiente) | `.toarray()` para ver |\n",
        "| **train_test_split** | Dividir datos en train/test | `test_size=0.2` |\n",
        "| **Stratify** | Mantener proporci√≥n de clases | `stratify=y` |\n",
        "\n",
        "### üß† Pipeline completo de procesamiento:\n",
        "\n",
        "```python\n",
        "# 1. Crear/cargar textos y etiquetas\n",
        "textos = [\"frase 1\", \"frase 2\", ...]\n",
        "etiquetas = [1, 0, ...]\n",
        "\n",
        "# 2. Vectorizar\n",
        "vectorizador = CountVectorizer()\n",
        "X = vectorizador.fit_transform(textos).toarray()\n",
        "y = np.array(etiquetas)\n",
        "\n",
        "# 3. Dividir\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 4. ¬°Entrenar modelo!\n",
        "# (esto lo ver√°s en el siguiente notebook)\n",
        "\n",
        "# 5. Transformar nuevas frases\n",
        "nueva_frase = [\"texto nuevo\"]\n",
        "X_nueva = vectorizador.transform(nueva_frase).toarray()\n",
        "```\n",
        "\n",
        "### üîë Puntos cr√≠ticos:\n",
        "\n",
        "1. **SIEMPRE vectoriza ANTES de dividir**\n",
        "2. **USA `fit_transform()` en train, `transform()` en test/nuevos**\n",
        "3. **NUNCA mezcles train y test**\n",
        "4. **USA `stratify` para mantener balance de clases**\n",
        "5. **GUARDA el vectorizador para usar en producci√≥n**\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ ¬øQu√© sigue?\n",
        "\n",
        "En el **Notebook 5** aprender√°s:\n",
        "- üß† **Keras**: Construir redes neuronales\n",
        "- üèóÔ∏è Capas densas (Dense)\n",
        "- ‚ö° Funciones de activaci√≥n (ReLU, Sigmoid)\n",
        "- üéØ Compilar y entrenar modelos\n",
        "- üìä Evaluar el rendimiento\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ AUTOEVALUACI√ìN\n",
        "\n",
        "Marca lo que has dominado:\n",
        "\n",
        "- [ ] Entender qu√© es Bag of Words\n",
        "- [ ] Crear Bag of Words manualmente\n",
        "- [ ] Usar CountVectorizer para vectorizar texto\n",
        "- [ ] Explorar el vocabulario generado\n",
        "- [ ] Analizar la matriz de caracter√≠sticas\n",
        "- [ ] Dividir datos con train_test_split\n",
        "- [ ] Usar stratify para mantener balance\n",
        "- [ ] Completar el pipeline de preprocesamiento\n",
        "- [ ] Transformar nuevas frases con el vectorizador\n",
        "\n",
        "---\n",
        "\n",
        "## üéâ ¬°FELICIDADES!\n",
        "\n",
        "Has completado el **Notebook 4: Procesamiento de Texto**.\n",
        "\n",
        "Ahora sabes c√≥mo preparar datos de texto para entrenar modelos de Deep Learning. Este conocimiento es fundamental para:\n",
        "- üìß Clasificaci√≥n de emails (spam/no spam)\n",
        "- üòä An√°lisis de sentimientos\n",
        "- üè∑Ô∏è Etiquetado autom√°tico de documentos\n",
        "- ü§ñ Chatbots y sistemas de di√°logo\n",
        "\n",
        "**üí™ ¬°Ya est√°s listo para construir tu primera red neuronal en el Notebook 5!**"
      ],
      "metadata": {
        "id": "summary"
      }
    }
  ]
}